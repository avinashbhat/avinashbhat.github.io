---
layout: post
title: Maths Prerequisites for Data Science and Machine Learning
description: Maths Prerequisites for Data Science and Machine Learning
summary: "Curated list of math resources."
date: 2020-05-15T00:00:00.000Z
category: exobrain
comments: true
tags:
  - roadmaps
  - data-science
  - machine-learning
  - probability
  - mathematics
published: true
---

In this interesting [article on LinkedIn](https://www.linkedin.com/pulse/mathematical-building-blocks-data-science-sam-savage/) by Sam Savage, he tells that 
>***"Data Scientists should not make statistical assumptions out of convention or computational convenience - use modern technology instead."***

This is something that I agree, being the conformist that I am. While it is easy to build a model and see it work, and to some extent explain it, never seems to be enough. This is the reason I put together few courses which are available for free on the internet, courtesy of good people at MIT, Harvard and others, which can get you the in depth knowledge required for a career in artificial intelligence.

The order that I have listed gives you a way to understand the concepts without having to go back for any other reading.

- [MIT - Single Variable Calculus](https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010/)
- [MIT - Multivariable Calculus](https://ocw.mit.edu/courses/mathematics/18-02sc-multivariable-calculus-fall-2010/)
- [Udacity - Introduction to Statistics](https://www.udacity.com/course/intro-to-statistics--st101)
- [Harvard - Statistics 110: Probability](https://projects.iq.harvard.edu/stat110/home)
- [MIT - Linear Algebra](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/)
- [fast.ai - Computational Linear Algebra](https://github.com/fastai/numerical-linear-algebra/blob/master/README.md)


If you read the article by Sam, you will come across Kolmogorov Complexity and Kullback-Leibler divergence, and here are a few resources for this.

- [Kolmogorov Complexity](https://people.cs.uchicago.edu/~fortnow/papers/kaikoura.pdf)
- [Kolmogorov Complexity on Brilliant](https://brilliant.org/wiki/kolmogorov-complexity/)
- [A Primer on Kolmogorov Complexity](https://jeremykun.com/2012/04/21/kolmogorov-complexity-a-primer/)
- [Kullback-Leibler Divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained)
- [Kullback-Leibler Divergence by Smoothing](http://hanj.cs.illinois.edu/cs412/bk3/KL-divergence.pdf)
- [Introduction to Kullback-Leibler Divergence](https://towardsdatascience.com/light-on-math-machine-learning-intuitive-guide-to-understanding-kl-divergence-2b382ca2b2a8)

He also has listed few references and further reading which are quite good.
